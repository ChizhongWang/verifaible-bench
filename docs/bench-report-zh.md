# VerifAIble Bench: 评测大语言模型从真实网页采集可验证证据的能力

> **VerifAIble Bench 评测报告**
>
> 发布日期：2026 年 2 月

---

## 摘要

大语言模型（LLM）在生成式任务中表现出色，但其"幻觉"问题严重制约了在高可信度场景中的落地。我们提出 **VerifAIble Bench**——首个端到端评测 LLM Agent「可验证证据采集」能力的基准。该基准包含 **21 个测试用例**，覆盖静态文本、HTML 表格、JavaScript 动态页面、PDF 文档和视频字幕五类证据来源，涉及中美金融监管门户网站。我们评测了 4 个模型（GLM-5、Kimi-K2.5、MiniMax-M2.5、DeepSeek-R1），采用"全有或全无"门控评分体系，从答案正确性、引用创建、引用内嵌和证据类型匹配四个维度打分。结果显示：**GLM-5 以满分 2100 分领先**，Kimi-K2.5 与 MiniMax-M2.5 并列 1680 分（均分 80.0），DeepSeek-R1 以 1080 分垫底。动态页面交互能力是模型间最大的区分度来源。

---

## 1. 引言

### 1.1 LLM 幻觉与 Grounding 需求

大语言模型在开放域问答、内容生成等任务中取得了显著进展，但其固有的"幻觉"（Hallucination）问题——即生成看似合理但事实错误的内容——严重限制了其在金融、法律、新闻等需要高可信度的领域中的应用。为解决此问题，业界广泛采用 Grounding（接地）策略，要求模型的输出能够追溯到可验证的原始来源。

### 1.2 现有 Benchmark 的不足

现有的 RAG（Retrieval-Augmented Generation）基准主要评测「检索质量」和「答案生成质量」，但存在以下盲区：

1. **缺少证据可验证性维度**：只关注答案是否正确，不关注答案是否能被第三方独立验证
2. **忽略真实网页交互**：多数基准基于预处理过的静态语料，未涉及 JavaScript 动态渲染、日期筛选、分页导航等真实网页操作
3. **缺乏证据采集链路评测**：从搜索→定位→交互→采集→引用的完整链路缺少系统性评估

### 1.3 VerifAIble 平台与 VerifAIble Bench

**VerifAIble** 是一个可验证证据管理平台，支持对网页证据进行高亮标注和回放验证。在此平台基础上，我们设计了 **VerifAIble Bench**，旨在评测 LLM Agent 完成「搜索 → 页面交互 → 数据采集 → 引用创建」完整链路的能力。

与传统 RAG 基准不同，VerifAIble Bench 要求模型不仅回答正确，还必须：
- 创建指向原始网页的可验证引用（Citation）
- 在答案文本中内嵌引用标记
- 采集正确类型的证据（文本/表格/PDF/视频）

---

## 2. 基准设计

### 2.1 测试集构成

VerifAIble Bench 包含 **21 个测试用例**，分布于五大类别：

| 类别 | 用例数 | 说明 | 难度 |
|------|--------|------|------|
| 静态文本（Text） | 6 | 从网页正文直接提取数据 | ★☆☆☆☆ |
| 静态表格（Table） | 7 | 从 HTML 表格定位特定行列数据 | ★★☆☆☆ |
| 动态页面（Dynamic） | 4 | 需执行 JS 操作（日期选择、分页）后采集表格数据 | ★★★★☆ |
| 动态+PDF（Dynamic+PDF） | 2 | 在动态页面中搜索并打开 PDF 文档提取信息 | ★★★★★ |
| 视频（Video） | 2 | 通过视频字幕提取特定信息 | ★★★☆☆ |

**数据源分布：**

| 数据源 | 用例数 | 域名 |
|--------|--------|------|
| 国家统计局 | 8 | stats.gov.cn |
| 上海证券交易所 | 6 | sse.com.cn |
| 中国证监会 | 1 | csrc.gov.cn |
| 美联储 | 3 | federalreserve.gov |
| 美国财政部 | 1 | treasury.gov |
| YouTube | 2 | youtube.com |

### 2.2 Agent 工具集

评测中的 LLM Agent 配备以下 **6 个工具**：

| 工具 | 功能 |
|------|------|
| `verifaible_web_search` | 搜索互联网获取相关页面 |
| `web_fetch` | 获取指定 URL 的网页内容 |
| `analyze_page` | 分析页面结构，识别关键元素和交互方式 |
| `test_action_steps` | 在页面上执行操作步骤（点击、输入、JS 执行），等价于浏览器自动化 |
| `verifaible_cite` | 创建可验证引用，保存证据快照 |
| `video_transcript` | 获取 YouTube 视频字幕内容 |

其中 `test_action_steps` 支持 `exec_js` 能力，可执行任意 JavaScript 代码（如设置日期选择器、触发 AJAX 请求、操作 DOM 元素），是完成动态页面任务的关键工具。

### 2.3 评分标准

VerifAIble Bench 采用 **All-or-Nothing（全有或全无）门控评分体系**：

**门控条件：** 如果答案不完全正确（answerCorrect ≠ 1.0），该用例总分直接为 **0 分**。

**四维度评分（满分 100 分）：**

| 维度 | 权重 | 说明 |
|------|------|------|
| 答案正确性（answerCorrect） | 40 | 模型答案是否包含所有期望关键字 |
| 引用创建（citationCreated） | 25 | 是否调用 `verifaible_cite` 创建了引用 |
| 引用内嵌（citationInText） | 15 | 答案文本中是否包含 `[@v:ID]` 引用标记 |
| 证据类型匹配（evidenceTypeMatch） | 20 | 引用的证据类型是否与期望一致 |

**评分公式：**

```
if answerCorrect < 1.0:
    totalScore = 0                          # 门控：答案错误直接零分
else:
    totalScore = 40
              + citationCreated × 25
              + citationInText  × 15
              + evidenceTypeMatch × 20
```

这意味着一个用例只有三种可能的分数：**100**（完美）、**80**（答案正确但证据类型不匹配）、**0**（答案错误）。

### 2.4 实验配置

| 配置项 | 值 |
|--------|-----|
| API | OpenRouter Responses API |
| 温度 | 0.3 |
| 最大轮次 | 30 |
| 会话隔离 | 每个 case 独立会话，无状态共享 |

---

## 3. 评测模型

本次评测选择了 4 个通过 OpenRouter 可调用的大语言模型：

| 模型 | 提供商 | 特点 |
|------|--------|------|
| **GLM-5** | 智谱 AI (Z-AI) | 新一代通用大模型，工具调用能力强 |
| **Kimi-K2.5** | 月之暗面 (Moonshot AI) | 擅长长文本理解，支持多模态 |
| **MiniMax-M2.5** | MiniMax | 高性价比模型，上下文窗口大 |
| **DeepSeek-R1** | DeepSeek | 推理专用模型，Chain-of-Thought 深度推理 |

---

## 4. 实验结果

### 4.1 总体排行

| 排名 | 模型 | 总分 | 均分 | 通过数 | 满分数 | 平均轮次 | 平均工具调用 | 总耗时 |
|------|------|------|------|--------|--------|----------|------------|--------|
| 🥇 | **GLM-5** | **2,100** | **100.0** | **21/21** | **21/21** | 7.7 | 6.7 | 55.7 min |
| 🥈 | **MiniMax-M2.5** | 1,680 | 80.0 | 17/21 | 16/21 | 10.6 | 9.7 | 71.3 min |
| 🥈 | **Kimi-K2.5** | 1,680 | 80.0 | 17/21 | 16/21 | 8.0 | 7.0 | 60.6 min |
| 4 | DeepSeek-R1 | 1,080 | 51.4 | 11/21 | 10/21 | 5.0 | 4.0 | 115.0 min |

> **注：** 通过数指总分 > 0 的用例数；满分数指总分 = 100 的用例数。

### 4.2 按类别分析

| 类别 | 用例数 | GLM-5 | MiniMax-M2.5 | Kimi-K2.5 | DeepSeek-R1 |
|------|--------|-------|-------------|-----------|-------------|
| 静态文本 | 6 | **600** (100%) | 580 (96.7%) | **600** (100%) | **600** (100%) |
| 静态表格 | 7 | **700** (100%) | **700** (100%) | 600 (85.7%) | 580 (82.9%) |
| 动态页面 | 4 | **400** (100%) | 0 (0%) | 100 (25%) | 0 (0%) |
| 动态+PDF | 2 | **200** (100%) | **200** (100%) | 180 (90%) | 0 (0%) |
| 视频 | 2 | **200** (100%) | **200** (100%) | **200** (100%) | 0 (0%) |

**关键发现：**

- **静态内容（文本+表格）**：四个模型差异较小，均能良好处理
- **动态页面是最大区分因素**：仅 GLM-5 完成全部 4 个动态 case，其余模型得分率为 0%–25%
- **视频理解**：除 DeepSeek-R1 外，其他模型均能通过 `video_transcript` 工具正确完成
- **DeepSeek-R1 在非静态场景全面失败**：动态、PDF、视频三类共 8 个 case 全部零分

### 4.3 Token 用量与效率分析

| 模型 | 输入 Token | 输出 Token | 总 Token | 输出/输入比 |
|------|-----------|-----------|---------|------------|
| GLM-5 | 1.87M | 31.5K | 1.90M | 1.7% |
| MiniMax-M2.5 | 3.45M | 54.4K | 3.51M | 1.6% |
| Kimi-K2.5 | 2.65M | 39.8K | 2.70M | 1.5% |
| DeepSeek-R1 | 1.02M | 160.2K | 1.18M | 15.7% |

**效率指标：**

| 模型 | 总分 | 总 Token | 总耗时 | 得分/万Token | 得分/分钟 |
|------|------|---------|--------|-------------|----------|
| **GLM-5** | 2,100 | 1.90M | 55.7 min | **11.1** | **37.7** |
| MiniMax-M2.5 | 1,680 | 3.51M | 71.3 min | 4.8 | 23.6 |
| Kimi-K2.5 | 1,680 | 2.70M | 60.6 min | 6.2 | 27.7 |
| DeepSeek-R1 | 1,080 | 1.18M | 115.0 min | 9.2 | 9.4 |

> GLM-5 在得分/Token 和得分/时间两个效率维度均大幅领先。

### 4.4 对话行为分析

| 模型 | 平均轮次 | 平均工具调用 | 平均输入 Token | 平均输出 Token | 平均耗时 |
|------|----------|------------|---------------|---------------|----------|
| GLM-5 | 7.7 | 6.7 | 88.9K | 1.5K | 2m39s |
| MiniMax-M2.5 | 10.6 | 9.7 | 164.4K | 2.6K | 3m24s |
| Kimi-K2.5 | 8.0 | 7.0 | 126.4K | 1.9K | 2m53s |
| DeepSeek-R1 | 5.0 | 4.0 | 48.4K | 7.6K | 5m29s |

**DeepSeek-R1 的 CoT 悖论：**
- 轮次最少（5.0 轮）、工具调用最少（4.0 次）
- 但输出 Token 是其他模型的 **3–5 倍**（7.6K vs 1.5–2.6K/轮）
- 耗时最长（5m29s/case）、得分最低（51.4 分）

这说明 R1 的 Chain-of-Thought 推理虽然产生了大量"思考"文本，但并未有效转化为更好的工具使用策略。相反，其较少的工具调用次数导致无法完成需要多步交互的复杂任务。

---

## 5. 深度分析

### 5.1 为什么 GLM-5 满分？

GLM-5 在全部 21 个用例中获得满分，其成功因素包括：

1. **高效的动态页面交互策略**：在面对上交所的日期选择器时，GLM-5 能够准确识别 DOM 结构并通过 `exec_js` 正确设置日期，通常在 10-28 轮内完成最复杂的动态任务
2. **精准的工具调用决策**：平均每个 case 仅需 6.7 次工具调用，做到了「刚好够用」
3. **稳定的引用创建**：100% 的引用创建率，每次都正确调用 `verifaible_cite` 并在文本中内嵌引用标记

### 5.2 动态页面是最大区分度来源

上交所（sse.com.cn）的 4 个动态页面 case 是整个基准中最具区分度的测试：

| Case | 任务 | GLM-5 | MiniMax | Kimi | R1 |
|------|------|-------|---------|------|-----|
| cn_dynamic_001 | 地方政府债成交笔数（日期筛选） | ✅ 100 | ❌ 0 | ✅ 100 | ❌ 0 |
| cn_dynamic_002 | 市值第一股票占比（日期筛选） | ✅ 100 | ❌ 0 | ❌ 0 | ❌ 0 |
| cn_dynamic_003 | 基金成交金额（日期筛选） | ✅ 100 | ❌ 0 | ❌ 0 | ❌ 0 |
| cn_dynamic_004 | 融券余量金额（日期筛选） | ✅ 100 | ❌ 0 | ❌ 0 | ❌ 0 |

**失败原因分析：**
- **日期设置失败**：MiniMax 和 Kimi 在 cn_dynamic_002–004 中都获取了错误日期的数据（例如将 2025-02-10 的数据与 2026-02-10 混淆），说明它们未能正确操作页面的日期筛选组件
- **轮次耗尽**：MiniMax 在 cn_dynamic_001 和 cn_dynamic_003 中耗尽了 30 轮上限仍未能完成
- **放弃尝试**：DeepSeek-R1 通常在 5-10 轮后就停止了工具调用，即使尚未获得正确答案

### 5.3 DeepSeek-R1 推理模型的悖论

DeepSeek-R1 作为以 Chain-of-Thought（CoT）推理著称的模型，在本基准中表现最差，呈现出明显的"推理-行动"悖论：

| 指标 | DeepSeek-R1 | 其他模型平均 | 差异 |
|------|-----------|------------|------|
| 平均输出 Token | 7,630 | 2,000 | **3.8×** |
| 平均轮次 | 5.0 | 8.8 | **0.57×** |
| 平均工具调用 | 4.0 | 7.8 | **0.51×** |
| 得分 | 51.4 | 86.7 | **0.59×** |
| 总耗时 | 115.0 min | 62.5 min | **1.84×** |

R1 将大量计算资源用于生成 CoT 推理文本，但这些推理并未转化为有效的工具使用行为：
- 在 cn_dynamic_003 中，R1 仅用 5 轮就产生了 31,201 个输出 Token（每轮 6,240 Token），但无一次成功的页面交互
- 在 cn_dynamic_pdf_001 和 cn_dynamic_pdf_002 中，R1 耗时近 19 分钟却无法找到目标 PDF

**结论**：对于需要「频繁工具调用 + 环境交互」的 Agent 任务，纯推理能力的提升无法弥补行动能力的不足。

---

## 6. 局限与展望

### 6.1 当前局限

1. **测试集规模有限**：仅 21 个用例，尚不足以覆盖所有可能的证据采集场景
2. **模型数量有限**：仅评测 4 个模型，未包含 GPT-4o、Claude 等主流模型
3. **数据源集中**：主要集中在中美金融监管网站，缺乏对其他领域的覆盖
4. **单次运行**：未进行多次重复实验以评估模型表现的稳定性
5. **无成本核算**：未对比各模型的 API 调用成本

### 6.2 未来工作

1. **扩展测试集**：增加至 100+ 用例，覆盖更多领域（医疗、法律、学术）
2. **纳入更多模型**：加入 GPT-4o、Claude、Gemini 等国际模型的横向对比
3. **多语言扩展**：增加日语、韩语等亚洲语言的测试场景
4. **稳定性评估**：每个 case 运行多次，评估模型表现的方差
5. **成本效率分析**：引入精确的 API 定价数据，计算性价比指标

---

## 附录

### 附录 A：完整得分矩阵

| # | Case ID | 类别 | 问题概要 | GLM-5 | MiniMax | Kimi | R1 |
|---|---------|------|----------|-------|---------|------|----|
| 1 | cn_text_001 | text | 2025年全国总人口 | 100 | 100 | 100 | 100 |
| 2 | cn_text_002 | text | 证监会证券监管局数量 | 100 | 100 | 100 | 100 |
| 3 | cn_text_table_001 | text/table | 2026年1月PMI | 100 | 100 | 100 | 100 |
| 4 | cn_table_001 | table | 螺纹钢1月下旬涨跌幅 | 100 | 100 | 100 | 100 |
| 5 | cn_table_002 | table | 郑州二手住宅价格同比 | 100 | 100 | **0** | **0** |
| 6 | cn_table_003 | table | 租赁房房租同比 | 100 | 100 | 100 | 100 |
| 7 | cn_table_004 | table | 耐用消费品同比 | 100 | 100 | 100 | 80 |
| 8 | cn_table_005 | table | 非制造业商务活动指数 | 100 | 100 | 100 | 100 |
| 9 | cn_table_006 | table | 螺纹钢2月上旬涨跌幅 | 100 | 100 | 100 | 100 |
| 10 | cn_dynamic_001 | dynamic | 地方政府债成交笔数 | 100 | **0** | 100 | **0** |
| 11 | cn_dynamic_002 | dynamic | 市值第一股票占比 | 100 | **0** | **0** | **0** |
| 12 | cn_dynamic_003 | dynamic | 基金成交金额 | 100 | **0** | **0** | **0** |
| 13 | cn_dynamic_004 | dynamic | 融券余量金额 | 100 | **0** | **0** | **0** |
| 14 | cn_dynamic_pdf_001 | dynamic+pdf | 中国黄金郑州分公司负责人 | 100 | 100 | 80 | **0** |
| 15 | cn_dynamic_pdf_002 | dynamic+pdf | 浦发银行每股净资产变动 | 100 | 100 | 100 | **0** |
| 16 | us_text_001 | text | IORB利率(2024.2) | 100 | 100 | 100 | 100 |
| 17 | us_text_002 | text | FOMC反对票 | 100 | 100 | 100 | 100 |
| 18 | us_text_003 | text | IORB利率下调至 | 100 | 80 | 100 | 100 |
| 19 | us_table_001 | table | 10年期国债收益率 | 100 | 100 | 100 | 100 |
| 20 | video_001 | video | Ken Robinson演讲引言 | 100 | 100 | 100 | **0** |
| 21 | video_002 | video | 神经网络输入层神经元数 | 100 | 100 | 100 | **0** |
| | | | **合计** | **2,100** | **1,680** | **1,680** | **1,080** |

### 附录 B：失败 Case 错误分析

| Case | 模型 | 失败原因 |
|------|------|----------|
| cn_table_002 | Kimi | 答案错误：未能从复杂表格中准确定位郑州二手住宅同比数据 |
| cn_table_002 | R1 | 答案错误：返回 91.1（正确值 90.9），可能读取了相邻行数据 |
| cn_table_004 | R1 | 证据类型不匹配：从正文文本而非表格提取数据（得 80 分） |
| cn_dynamic_001 | MiniMax | 轮次耗尽：30 轮内未能完成日期设置 |
| cn_dynamic_001 | R1 | 日期设置错误：获取了错误日期的数据（167 笔 vs 正确 61 笔） |
| cn_dynamic_002 | MiniMax, Kimi | 日期混淆：返回 5.33%（2026年数据）而非 3.97%（2025年数据） |
| cn_dynamic_002 | R1 | 日期混淆：未能正确切换到 2025 年 2 月数据 |
| cn_dynamic_003 | MiniMax | 轮次耗尽：30 轮内未完成 |
| cn_dynamic_003 | Kimi | 轮次耗尽：30 轮内未完成 |
| cn_dynamic_003 | R1 | 放弃尝试：仅 5 轮后停止，产生大量 CoT 文本但无有效操作 |
| cn_dynamic_004 | MiniMax, Kimi, R1 | 日期混淆 / 部分匹配：均获取了错误日期的融券数据 |
| cn_dynamic_pdf_001 | R1 | 无法导航：未能在公告页面找到目标 PDF |
| cn_dynamic_pdf_001 | Kimi | 证据类型不匹配：答案正确但引用为 text 而非 pdf（得 80 分） |
| cn_dynamic_pdf_002 | R1 | 无法导航：未能在公告页面找到目标 PDF |
| us_text_003 | MiniMax | 证据类型不匹配：引用为 pdf 而非 text（得 80 分） |
| video_001 | R1 | 答案匹配失败：包含正确引言但评分引擎未能匹配完整短语 |
| video_002 | R1 | 未创建引用：回答了问题但未调用 `verifaible_cite` |

### 附录 C：Token 用量明细

| 模型 | 总输入 Token | 总输出 Token | 总 Token | 平均输入/Case | 平均输出/Case |
|------|-------------|-------------|---------|--------------|--------------|
| GLM-5 | 1,866,536 | 31,507 | 1,898,043 | 88,883 | 1,500 |
| MiniMax-M2.5 | 3,453,171 | 54,435 | 3,507,606 | 164,437 | 2,592 |
| Kimi-K2.5 | 2,654,870 | 39,759 | 2,694,629 | 126,422 | 1,893 |
| DeepSeek-R1 | 1,016,392 | 160,241 | 1,176,633 | 48,400 | 7,631 |

---

*完整数据集和代码开源于 [verifaible-bench](https://github.com/verifaible/verifaible-bench) 仓库。*
